# 100DaysOfMLCode
This repo shows my daily activity of Machine Learning's 100DaysOfMLCode challenge. This is a challenge and pledge to study and learn Machine Learning at least  an hour daily.

Thanks for [Suryaprakash Reddy](https://github.com/SurajChinna) and Siraj Raval from YouTube for this idea and initive.

***
Need to check this daily: (https://github.com/SakaSaiTrinath/Learn_Machine_Learning_in_3_Months)
***

## Day 0: 15 Aug, 2018
Started Udacity's course: [Intro to Machine Learning]( https://in.udacity.com/course/intro-to-machine-learning--ud120-india)

Completed Lesson 1: Welcome to Macine Learning.

Really excited and motivated to learn something extraordinarily with a discipline.

## Day 1: 16 Aug, 2018
completed half of Lesson 2: Naive bayes

Taking time for completing but instructors' explanation is really marvellous. They are involving real life examples and data to explain the things. Excited to continue this course.

## Day 2: 17 Aug, 2018
Completed Lesson2: Naive Bayes Algorithm. 

Doing a mini project which is given at the end of the Lesson: To find the author from their email writings. I need to implement Naive Bayes Algorithm to do this mini project in python.

Going well till now. The way the course set is wonderful. Every piece by piece of the concept is clearly explained by the instructors. Involving me in the quizzes made me understand very quickly and easily.

## Day 3: 18 Aug, 2018
Working on the mini project.

Setting up the required environment for the project. Downloading the data sets and project material needed for the project and for the course future activities.

Almost learnt nothing new today. Felt disappointing.

## Day 4: 19 Aug, 2018
Still working on the project.

Hard to solve but will be done for sure.

## Day 5: 20 Aug, 2018
Completed the project.

That was a very easy one. I wasn't got it yesterday. Anyhow delighted now for completing it. Going on to next Lesson SVM algorithm.

## Day 6: 21 Aug, 2018
Completed half of the Lesson SVMs: Support Vector Machines.

This is a gret algorithm which also solves the non-linear problems unlike naive_bayes. At the middle of lesson, Excited to move forward to know more about it and implement it.

## Day 7: 22 Aug, 2018
Got a mini project today. Project problem is same as the last one done with naive_bayes. Now I have to use SVC of SVM to solve the problem.

It's really taking a lot of time to train the data in my machine. It is reflecting in my learning pace. I couldn't move forward if it troubles me like this.

## Day 8: 23 Aug, 2018
Statrted a new video series by Daniel Shiffman from coding train, youtube.

Although it is based on javascript, but it is completely focusing on Machine Learning. Completed its first session 1: Algorithms and graphs earlier. Today headed over to session 2: Genetic Algorithms. 

To complete mini project, It is taking a lot of time to train and test the data. If I code wrong, modify it and try test run again, it takes a lot of time in my machine. So, I started a new series.

## Day 9: 24 Aug, 2018
 Completed two videos in the series and worked on them.
 
These videos focused on Evolutionary Computing, and more specifically, Genetic Algorithms. In this tutorial, I got introduced to the concept of a genetic algorithm, how it can be used to approach "search" problems and how it relates to brute force algorithms.

## Day 10: 25 Aug, 2018
Almost completed the second mini project.

A small problem in last task in the project which needed to be figured out. The ice is slowly breaking now. Everything started feeling familiar and feel like becoming a part of ML slowly.

## Day 11: 26 Aug, 2018
Completed the 2nd mini project successfully.

Solving problems, cracking them, understanding them and implementing them making things more clear. Anyway do and learn is really appreciable approach which is helping me understand the ML quickly and betterly.

## Day 12: 27 Aug, 2018
Learnt about Activation functions and Backpropagation algorithm.

Learnt and practised these concepts which have been taught in the class today. Understanding them to the clearer picture what they really do and what is their importance in Machine Learning.
 
## Day 13: 28 Aug, 2018
Completed half of the next Lesson: Decision Trees.

Going great. New algorithm Decision Trees making more sense and looks brilliant. Need to learn more.

## Day 14: 29 Aug, 2018
Revised the topics learnt till today.

OfCourse there is a lot more to learn but without remembering the learnt things will be just wasted. So, today's one hour is dedicated to revision and analysis of things learnt till today.

## Day 15: 30 Aug, 2018
Due to network problem, this commit has done with the next day's commit.

Practiced Neural Networks, Perceptron in program in python.

## Day 16: 31 Aug, 2018
Watched Genetic Algorithm video from the Youtube series.

Learnt and practiced the genetic algorithm: generating a desired string using genetic algorithm which uses 3 features - Heredity, Variation and Mutation.

This algorithm astonished me which Darwin found how species evaluate using those 3 features.

## Day 17: 1 Sep, 2018
Spent learning more about Genetic Algorithm: Shakespear Monkey problem, fitness function, improving fitness function, pool selection algorithm based on weights.

Coding something knowingly gives us more boosting as things are done by your awareness. This is situation I am in.

## Day 18: 2 Sep, 2018
Learnt Another algorithm for Pool selection, and interactive selection.

Literally you need a final output which is known, and you want it to built from scratch with some sort of algorithms or coding or something. Then this Genetic algorithm is very useful in that case.

Through interactive selection, we can design an output with the user's interaction or user's data. We can say, we can get the users feedback every time and improve our product every time. Finally we get a user's most desired output.

## Day 19: 3 Sep, 2018
Practiced Genetic Algorithm. Spent time to understand it properly and deeply.

Digging deep into Genetic algorithm is really widening my understanding. The more detailed understanding helps us in using it where it can be. Genetic algorithm came from the Darwinian theory that is from nature. So observing nature really solves our many problems. When somebody don't get solution they may find it in nature.

## Day 20: 4 Sep, 2018
Revised and practiced Neural Networks, Perceptron, Mcculloh-Pitts neuron, backpropagation algorithm, all with different activation functions by theoritically and implementing in python.

## Day 21: 5 Sep, 2018
Watched half of smart rockets project series by Daniel Shiffman in youtube.

This project is about an evolutionary steering behaviors coding challenge. The goal is to create a system where autonomous steering agents evolve the behavior of eating food (green dots) and avoiding poison (red dots).

## Day 22: 6 Sep, 2018
Tried to implement the same project which I watched yesterday but I supposed to know about steering behaviors to code this before. Because the rockets which finds food needs to change their path to food from their current going path.

I could not go completely in learning steering behaviors (it may make my path off the track) but tried to learn how the code work so that I could able to implement it.

Today spent checking the code, understanding it well.

## Day 23: 7 Sep, 2018
Completed all the series of the project. I am skipping implementation it beacause I am having Supervised and Unsupervised learning going on in my engineering class but I am going with Genetic Algorithms here So I could not fulfill the both.

This is the bad approach I have done. I shouldn't have had started this series but still I got good understanding of Genetic Algorithms.
Now, I am moving towards the new Session of Coding Train's Intelligence and Learning and need to complete Udacity's course I stopped it at Decision tree. I need to revert back to them.

## Day 24: 8 Sep, 2018
Completed Decision trees lesson, got an project to do.

Need to do the same project which have done in lesson 1 and 2 but this time, using decision tress.

## Day 25: 9 Sep, 2018
Completed  half of mini project. 

Project is easy but it takes time to complete. Nearly 10 - 15 mins for executing one time on my machine. If any mistake, the position is like, you are going to bear your time everytime. For every change and execute, it takes a lot time.

## Day 26: 10 Sep, 2018
Completed the whole mini project using decision trees. 

finally, Although it is taking time to complete, I could able to complete the project.

## Day 27: 11 Sep, 2018
Started Session 3: Intro to Machine Learning from the course of Intelligence and Learning of Coding Train by Daniel Shiffman.

Shiffman has his own way of explaining things. Honestly, I have got a clear cut overview of Machine Learning today. He has got videos which I haven't touched upon. This would help me in learning Machine Learning in different views.

## Day 28: 12 Sep, 2018
Started New Lesson "Choose Your Own Algorithm" of Udacity course.

This is not a teaching lesson but like a practical session. The purpose of this lesson is that I have to select my own algorithm and learn it and try to apply it to my data sets and get the accuracy. Their intention behind this lesson is that a Machine Learning Practioner should do the things on his own whatever they are trying make me do is the machine learning engineer does throught his ML journey.

#### Due to the exams, this is stopped for a while. It will be continued after the exams.

## Day 29: 26 Sep, 2018
It's almost 14 days taking break to this challenge due to exams and took some extra days for a fresh start for the challenge. Took extra days to complete some other courses and projects. So, I can devote my time daily to this challenge.

Today I picked up from where I left. Udacity's course - choosing my algorithm. I chose the Random Forest algorithm. In this lesson, I have to study the algorithm, learn it and have to apply on the dataset given by them and calculate the accuracy.

I understand the algorithm today in outline and looked into sklearn documentation of random forest classifer, understood some of the parameters and tried to implement them. It is taking a lot of time to run on my machine. I need to check this up tomorrow.

## Day 30: 27 Sep, 2018
It's about a month of #100DaysOfMLCode challenge. Going fine till day. Learning is something needs to move on and on to sharp yourself. I hope this challenge gives a good starting for my ML journey.

Today, I completed the Lesson8 by learning a new algorithm, implementing it and calculating the accuracy. Then, next task for me was to beat the accuracy score of 93.6% done by the instructors in the videos. I finally beat with the K Nearest Neighbor algorithm. It is really superb in classification. All the other algorithms I tried were taking a lot of time and couldn't able to give good accuracy score but this algorithm run in 0.109 seconds (Really WOW!!!) and achieved 94% in the first try itself and I could able to beat the instructor's accuracy score.

## Day 31: 28 Sep, 2018
Today started Lesson 10: Datasets
It's about enron dataset. enron is a company where it was bankrupted by the some of the employees and others. Instructor is trying to teach how to work on the dataset, how can we understand the dataset with our targeted questions till now.

Machine Learning really makes wonders that is we can literally find answers to many questions using machines easily. We should have deep understanding of algorithms, data we need, how can we train the machine, test it using test cases everything matters. If we could able to understand all these damn sure we can find answer to any question.


## Day 32: 29 Sep, 2018
Continuing Datasets lesson.
It is really interesting to find about the story of enron and I am excited to see how Machine Learning practioners proceed from collecting data to achieve the objective.

Today is all about analysing the dataset and understanding its structure.

## Day 33: 30 Sep, 2018:
Completed two-thirds of the lesson.
Today is all about quizzes. Most of the lesson is comrised of quizzes. Some of the quizzes are not on the dataset but depends on research. I have to do the research on the enron company and need to find about the big hands behind the case. 

I am understanding to know the value of research and its importance which gathers more knowledge to solve the problems. As if you have more data, your accuracy levels increases, the same if you have more knowledge about the case-study we are doing, the more successful it would be.

## Day 33: 31 Sep, 2018:
Completed the Datasets and questions lesson.
Today is all bout "NaN". Many fields in the dataset doesn't contain which is denoted by NaN in the dataset. The whole topic is "NaN" really matters in the dataset. It effects the results of the queries performed. Adding data also effects the results. We need to consider it very well. So, finally at the end of the day: NaN matters in dataset.

## Day 34: 1 Oct, 2018:
Today spent on the revision of what I have learnt till now. Need more time to do this too. Today is getting a overview on all the learnt topics. This evalution helps whether I am going on the correct path or not.

## Day 35: 2 Oct, 2018:
Learning hybrid systems which has taught in the engineering class of Machine Learning. My thoughts are like Machine Learning can help Machine Learning to solve one problem of another. Like Neural Networks need weights to learn about the given scenario of the data. But they would be random weights. So, it might take a lot of time to learn. We can solve this issue by genetic algorithm because genetic algorithms approached quickly towards the destination. So, this way one area of ML can help another area of ML.

Not only that, combination of different areas of Machine Learning produces hybrid systems.

## Day 36: 3 Oct, 2018
Implemeting the Neural Networks with Genetic algorithms of hybrid systems. Taking the scenario of some imaginary inputs and desired outputs and implemented them in Neural Networks with backpropagation and observed the weights changing.

Observed the weights generated, errors variation with variation of learning rate and the time taken for different learning rates. Every time the statistics and I couldn't get any conclusion. The whole scenario might depend upon the machine we are using and processes it processing at that time of program execution.

## Day 37: 4 Oct, 2018
Today continuing the implemention with using the same imaginary inputs and desired outputs but not with backpropagation this time, and with genetic algorithm. 

It is some problem with implementing with genetic algorithms because it needs more assumptions to implement the genetic algorithms. It changes to every problem we consider. But finally I could able to implement at the end after a lot of trials.

## Day 38: 5 Oct, 2018
Learning fuzzy logic and implementing in code.
It is taught in class about the fuzzy logic and systems earlier. Today I spent more time to understand it. Simply fuzzy logic can be explained this way - In daily life we use words and adjectives which doesn't have accurate value; for suppose, we say - He is driving at average speed. (But what is that average speed. is it 60 or 80 or 90. It may vary from one to one again); we say - I'm speaking quietly. (How much sound is that? how many decibles measures quite?). These type of fuzzy statements are handled and programmed to get the desired results.

For example, we went to restaurant and we have to decide to pay tip to bearer at the end of the meals from 1 to 25 rupees depend upon the factors - quality of the food served with tags - poor, medium and good, and the quality of service with the tags - poor, medium and good. How can we make a system to learn to decide the tip based on these factors. It is handled by the fuzzy logic and systems.

## Day 39: 6 Oct, 2018
Started Lesson 11: Regression 
Today learnt about the differenc between continous and descrete factors and the difference between supervised learning and regression.

## Day 40: 7 Oct, 2018
Completed half of the lesson.
Learnt the regression with the slope and intercept, predictions using regression. Coding the regression using sklearn. Learnt about the r squared value and its importance in regression and how it is better than sum of squared errors.

## Day 41: 8 Oct, 2018
Completed the lesson.
Learnt multivariate regression. Although it is difficult to represent but easy to understand. Got mini project - I have to implement the regression on the enron dataset got in the last lession.

I got an idea how to represent the data in graph view. It will give an idea of how the data is responding to the operations we performed on it.

## Day 42: 9 Oct, 2018
Today spent time on the visualization of the data. I practiced and tried to understand how to represent data accordingly so we get some inference from the data. I tried different graph and plots on the data and try to understand which plot is to be applied on which data which gives good inference.

